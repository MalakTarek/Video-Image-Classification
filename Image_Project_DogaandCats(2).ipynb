{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python numpy pandas matplotlib scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nader Labib\\Documents\\vs code\\indentationCamp\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'gamma': 'scale'}\n",
      "Validation Accuracy: 0.653125\n",
      "SVM Test Accuracy: 0.66\n",
      "Precision: 0.6605156787426878\n",
      "Recall: 0.6598414960374009\n",
      "F1-score: 0.6595829891617231\n",
      "Confusion Matrix: \n",
      "[[125  74]\n",
      " [ 62 139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nader Labib\\Documents\\vs code\\indentationCamp\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nader Labib\\Documents\\vs code\\indentationCamp\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - accuracy: 0.5179 - loss: 0.8018 - val_accuracy: 0.4500 - val_loss: 0.7050\n",
      "Epoch 2/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 256ms/step - accuracy: 0.5259 - loss: 0.6860 - val_accuracy: 0.4500 - val_loss: 0.6935\n",
      "Epoch 3/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step - accuracy: 0.5264 - loss: 0.6882 - val_accuracy: 0.4656 - val_loss: 0.6979\n",
      "Epoch 4/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.5787 - loss: 0.6671 - val_accuracy: 0.5750 - val_loss: 0.6534\n",
      "Epoch 5/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 229ms/step - accuracy: 0.6071 - loss: 0.6488 - val_accuracy: 0.5562 - val_loss: 0.7038\n",
      "Epoch 6/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 226ms/step - accuracy: 0.6503 - loss: 0.6172 - val_accuracy: 0.5844 - val_loss: 0.6805\n",
      "Epoch 7/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 227ms/step - accuracy: 0.6587 - loss: 0.6040 - val_accuracy: 0.6281 - val_loss: 0.6167\n",
      "Epoch 8/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 242ms/step - accuracy: 0.6516 - loss: 0.6241 - val_accuracy: 0.6500 - val_loss: 0.6289\n",
      "Epoch 9/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 234ms/step - accuracy: 0.6960 - loss: 0.5927 - val_accuracy: 0.6500 - val_loss: 0.6035\n",
      "Epoch 10/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 234ms/step - accuracy: 0.6706 - loss: 0.5896 - val_accuracy: 0.6687 - val_loss: 0.5869\n",
      "Epoch 11/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 229ms/step - accuracy: 0.6647 - loss: 0.5860 - val_accuracy: 0.5938 - val_loss: 0.7194\n",
      "Epoch 12/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 228ms/step - accuracy: 0.6894 - loss: 0.5647 - val_accuracy: 0.6531 - val_loss: 0.6297\n",
      "Epoch 13/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 232ms/step - accuracy: 0.7155 - loss: 0.5554 - val_accuracy: 0.6062 - val_loss: 0.6306\n",
      "Epoch 14/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 236ms/step - accuracy: 0.6883 - loss: 0.5781 - val_accuracy: 0.6531 - val_loss: 0.6252\n",
      "Epoch 15/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 229ms/step - accuracy: 0.7292 - loss: 0.5483 - val_accuracy: 0.5813 - val_loss: 0.6887\n",
      "Epoch 16/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 228ms/step - accuracy: 0.7554 - loss: 0.5200 - val_accuracy: 0.6938 - val_loss: 0.5835\n",
      "Epoch 17/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 226ms/step - accuracy: 0.7113 - loss: 0.5578 - val_accuracy: 0.7031 - val_loss: 0.5504\n",
      "Epoch 18/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 231ms/step - accuracy: 0.7247 - loss: 0.5548 - val_accuracy: 0.7375 - val_loss: 0.5607\n",
      "Epoch 19/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 229ms/step - accuracy: 0.7286 - loss: 0.5389 - val_accuracy: 0.6625 - val_loss: 0.6009\n",
      "Epoch 20/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 231ms/step - accuracy: 0.7145 - loss: 0.5653 - val_accuracy: 0.6969 - val_loss: 0.5838\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7090 - loss: 0.5649\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
      "CNN Test Accuracy: 0.7125\n",
      "Precision: 0.7134183059012444\n",
      "Recall: 0.7126553163829096\n",
      "F1-score: 0.7122824135752663\n",
      "Confusion Matrix: \n",
      "[[148  51]\n",
      " [ 64 137]]\n",
      "SVM Metrics: {'accuracy': 0.66, 'precision': 0.6605156787426878, 'recall': 0.6598414960374009, 'f1_score': 0.6595829891617231}\n",
      "CNN Metrics: {'accuracy': 0.7125, 'precision': 0.7134183059012444, 'recall': 0.7126553163829096, 'f1_score': 0.7122824135752663}\n",
      "CNN outperforms SVM in terms of accuracy.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define constants\n",
    "IMG_SIZE = (128, 128)\n",
    "N_CLUSTERS = 100\n",
    "\n",
    "# Data collection and preprocessing\n",
    "def load_images_from_folder(folder, labels_df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, IMG_SIZE)\n",
    "            images.append(img)\n",
    "            label = labels_df.loc[labels_df['image'] == filename, 'labels'].values[0]\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def preprocess_images(images):\n",
    "    images = images / 255.0\n",
    "    return images\n",
    "\n",
    "data_folder = r'C:\\Users\\Nader Labib\\Documents\\vs code\\indentationCamp\\DogaCato\\cat_dog1'\n",
    "labels_csv = r'C:\\Users\\Nader Labib\\Documents\\vs code\\indentationCamp\\DogaCato\\cat_dog1.csv'\n",
    "labels_df = pd.read_csv(labels_csv)\n",
    "\n",
    "images, labels = load_images_from_folder(data_folder, labels_df)\n",
    "images = preprocess_images(images)\n",
    "label_to_idx = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "labels = np.array([label_to_idx[label] for label in labels])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# SIFT Feature Extraction and Bag-of-Words\n",
    "def extract_sift_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    descriptors_list = []\n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_BGR2GRAY)  # Convert to 8-bit before grayscale conversion\n",
    "        _, descriptors = sift.detectAndCompute(gray, None)\n",
    "        if descriptors is not None:\n",
    "            descriptors_list.append(descriptors)\n",
    "    return descriptors_list\n",
    "\n",
    "def build_vocabulary(descriptors_list, n_clusters):\n",
    "    all_descriptors = np.vstack(descriptors_list)\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(all_descriptors)\n",
    "    return kmeans\n",
    "\n",
    "def compute_bow_histograms(descriptors_list, kmeans):\n",
    "    histograms = []\n",
    "    for descriptors in descriptors_list:\n",
    "        if descriptors is not None:\n",
    "            predictions = kmeans.predict(descriptors)\n",
    "            hist, _ = np.histogram(predictions, bins=range(kmeans.n_clusters + 1), density=True)\n",
    "        else:\n",
    "            hist = np.zeros(kmeans.n_clusters)\n",
    "        histograms.append(hist)\n",
    "    return np.array(histograms)\n",
    "\n",
    "sift_train_descriptors = extract_sift_features(X_train)\n",
    "kmeans = build_vocabulary(sift_train_descriptors, N_CLUSTERS)\n",
    "X_train_bow = compute_bow_histograms(sift_train_descriptors, kmeans)\n",
    "\n",
    "sift_val_descriptors = extract_sift_features(X_val)\n",
    "X_val_bow = compute_bow_histograms(sift_val_descriptors, kmeans)\n",
    "\n",
    "sift_test_descriptors = extract_sift_features(X_test)\n",
    "X_test_bow = compute_bow_histograms(sift_test_descriptors, kmeans)\n",
    "\n",
    "# Standardize BOW features\n",
    "scaler = StandardScaler()\n",
    "X_train_bow = scaler.fit_transform(X_train_bow)\n",
    "X_val_bow = scaler.transform(X_val_bow)\n",
    "X_test_bow = scaler.transform(X_test_bow)\n",
    "\n",
    "# SVM Classifier\n",
    "def train_svm(X_train, y_train, X_val, y_val):\n",
    "    parameters = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}\n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(svc, parameters)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f\"Best parameters: {clf.best_params_}\")\n",
    "    best_svc = clf.best_estimator_\n",
    "    y_val_pred = best_svc.predict(X_val)\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred)}\")\n",
    "    return best_svc\n",
    "\n",
    "best_svc = train_svm(X_train_bow, y_train, X_val_bow, y_val)\n",
    "\n",
    "# Evaluate SVM\n",
    "y_test_pred = best_svc.predict(X_test_bow)\n",
    "print(f\"SVM Test Accuracy: {accuracy_score(y_test, y_test_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred, average='macro')}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred, average='macro')}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_test_pred, average='macro')}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_test_pred)}\")\n",
    "\n",
    "# CNN Model\n",
    "def create_cnn(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(label_to_idx)\n",
    "cnn_model = create_cnn(input_shape, num_classes)\n",
    "\n",
    "# Train CNN with augmented data\n",
    "\n",
    "batch_size = 32\n",
    "cnn_model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Summary of results\n",
    "y_test_pred_cnn = np.argmax(cnn_model.predict(X_test), axis=-1)\n",
    "print(f\"CNN Test Accuracy: {accuracy_score(y_test, y_test_pred_cnn)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred_cnn, average='macro')}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred_cnn, average='macro')}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_test_pred_cnn, average='macro')}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_test_pred_cnn)}\")\n",
    "\n",
    "# Comparison and Analysis\n",
    "def compare_models(svm_metrics, cnn_metrics):\n",
    "    print(f\"SVM Metrics: {svm_metrics}\")\n",
    "    print(f\"CNN Metrics: {cnn_metrics}\")\n",
    "    if svm_metrics['accuracy'] > cnn_metrics['accuracy']:\n",
    "        print(\"SVM outperforms CNN in terms of accuracy.\")\n",
    "    else:\n",
    "        print(\"CNN outperforms SVM in terms of accuracy.\")\n",
    "    # Additional analysis can be added here\n",
    "\n",
    "svm_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'precision': precision_score(y_test, y_test_pred, average='macro'),\n",
    "    'recall': recall_score(y_test, y_test_pred, average='macro'),\n",
    "    'f1_score': f1_score(y_test, y_test_pred, average='macro')\n",
    "}\n",
    "\n",
    "cnn_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_test_pred_cnn),\n",
    "    'precision': precision_score(y_test, y_test_pred_cnn, average='macro'),\n",
    "    'recall': recall_score(y_test, y_test_pred_cnn, average='macro'),\n",
    "    'f1_score': f1_score(y_test, y_test_pred_cnn, average='macro')\n",
    "}\n",
    "\n",
    "compare_models(svm_metrics, cnn_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with Adam optimizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nader Labib\\Documents\\vs code\\indentationCamp\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nader Labib\\Documents\\vs code\\indentationCamp\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 229ms/step - accuracy: 0.4945 - loss: 1.0257 - val_accuracy: 0.5500 - val_loss: 0.6921\n",
      "Epoch 2/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 226ms/step - accuracy: 0.4794 - loss: 0.6938 - val_accuracy: 0.4500 - val_loss: 0.6934\n",
      "Epoch 3/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 0.5382 - loss: 0.6919 - val_accuracy: 0.5094 - val_loss: 0.6933\n",
      "Epoch 4/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - accuracy: 0.5660 - loss: 0.6849 - val_accuracy: 0.5938 - val_loss: 0.6765\n",
      "Epoch 5/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - accuracy: 0.5656 - loss: 0.6804 - val_accuracy: 0.5375 - val_loss: 0.6936\n",
      "Epoch 6/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - accuracy: 0.5958 - loss: 0.6704 - val_accuracy: 0.5906 - val_loss: 0.6692\n",
      "Epoch 7/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.6057 - loss: 0.6623 - val_accuracy: 0.5063 - val_loss: 0.7151\n",
      "Epoch 8/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.5875 - loss: 0.6618 - val_accuracy: 0.6156 - val_loss: 0.6749\n",
      "Epoch 9/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.5979 - loss: 0.6406 - val_accuracy: 0.5375 - val_loss: 0.6765\n",
      "Epoch 10/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.6463 - loss: 0.6299 - val_accuracy: 0.5750 - val_loss: 0.6602\n",
      "Epoch 11/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.6199 - loss: 0.6296 - val_accuracy: 0.6000 - val_loss: 0.6557\n",
      "Epoch 12/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 278ms/step - accuracy: 0.6599 - loss: 0.6031 - val_accuracy: 0.5625 - val_loss: 0.6631\n",
      "Epoch 13/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 238ms/step - accuracy: 0.6763 - loss: 0.5927 - val_accuracy: 0.6875 - val_loss: 0.6172\n",
      "Epoch 14/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 226ms/step - accuracy: 0.6975 - loss: 0.5867 - val_accuracy: 0.7094 - val_loss: 0.5625\n",
      "Epoch 15/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.7157 - loss: 0.5559 - val_accuracy: 0.6156 - val_loss: 0.6545\n",
      "Epoch 16/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 226ms/step - accuracy: 0.6715 - loss: 0.5869 - val_accuracy: 0.6844 - val_loss: 0.5801\n",
      "Epoch 17/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 0.7176 - loss: 0.5526 - val_accuracy: 0.7156 - val_loss: 0.5679\n",
      "Epoch 18/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 235ms/step - accuracy: 0.6942 - loss: 0.5808 - val_accuracy: 0.6656 - val_loss: 0.6134\n",
      "Epoch 19/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - accuracy: 0.7264 - loss: 0.5453 - val_accuracy: 0.6438 - val_loss: 0.6548\n",
      "Epoch 20/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 229ms/step - accuracy: 0.7078 - loss: 0.5384 - val_accuracy: 0.7031 - val_loss: 0.5645\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7125 - loss: 0.5672\n",
      "Test Accuracy with Adam optimizer: 0.7149999737739563\n",
      "Training model with SGD optimizer...\n",
      "Epoch 1/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 215ms/step - accuracy: 0.5157 - loss: 0.6958 - val_accuracy: 0.4531 - val_loss: 0.6987\n",
      "Epoch 2/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.5120 - loss: 0.6905 - val_accuracy: 0.4500 - val_loss: 0.7000\n",
      "Epoch 3/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 195ms/step - accuracy: 0.5343 - loss: 0.6912 - val_accuracy: 0.4719 - val_loss: 0.6945\n",
      "Epoch 4/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.5509 - loss: 0.6841 - val_accuracy: 0.5844 - val_loss: 0.6837\n",
      "Epoch 5/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.5310 - loss: 0.6867 - val_accuracy: 0.5719 - val_loss: 0.6840\n",
      "Epoch 6/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.5593 - loss: 0.6824 - val_accuracy: 0.5469 - val_loss: 0.6833\n",
      "Epoch 7/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.5563 - loss: 0.6853 - val_accuracy: 0.6187 - val_loss: 0.6755\n",
      "Epoch 8/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 213ms/step - accuracy: 0.5735 - loss: 0.6816 - val_accuracy: 0.5906 - val_loss: 0.6716\n",
      "Epoch 9/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.5660 - loss: 0.6822 - val_accuracy: 0.5094 - val_loss: 0.6912\n",
      "Epoch 10/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.5723 - loss: 0.6787 - val_accuracy: 0.5688 - val_loss: 0.6793\n",
      "Epoch 11/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.5708 - loss: 0.6765 - val_accuracy: 0.5938 - val_loss: 0.6736\n",
      "Epoch 12/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.5749 - loss: 0.6764 - val_accuracy: 0.5938 - val_loss: 0.6633\n",
      "Epoch 13/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.5860 - loss: 0.6711 - val_accuracy: 0.4563 - val_loss: 0.7174\n",
      "Epoch 14/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.5668 - loss: 0.6789 - val_accuracy: 0.6094 - val_loss: 0.6650\n",
      "Epoch 15/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.5946 - loss: 0.6715 - val_accuracy: 0.6062 - val_loss: 0.6676\n",
      "Epoch 16/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.6028 - loss: 0.6665 - val_accuracy: 0.5906 - val_loss: 0.6574\n",
      "Epoch 17/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 203ms/step - accuracy: 0.6040 - loss: 0.6644 - val_accuracy: 0.5906 - val_loss: 0.6703\n",
      "Epoch 18/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step - accuracy: 0.6139 - loss: 0.6654 - val_accuracy: 0.6125 - val_loss: 0.6571\n",
      "Epoch 19/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - accuracy: 0.6125 - loss: 0.6613 - val_accuracy: 0.5625 - val_loss: 0.6851\n",
      "Epoch 20/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.5705 - loss: 0.6635 - val_accuracy: 0.6250 - val_loss: 0.6547\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.6224 - loss: 0.6551\n",
      "Test Accuracy with SGD optimizer: 0.6175000071525574\n",
      "Training model with RMSprop optimizer...\n",
      "Epoch 1/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - accuracy: 0.4922 - loss: 0.9753 - val_accuracy: 0.5813 - val_loss: 0.6800\n",
      "Epoch 2/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.5529 - loss: 0.6945 - val_accuracy: 0.4563 - val_loss: 0.6889\n",
      "Epoch 3/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.5584 - loss: 0.6857 - val_accuracy: 0.5969 - val_loss: 0.6786\n",
      "Epoch 4/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - accuracy: 0.5727 - loss: 0.6830 - val_accuracy: 0.4563 - val_loss: 0.8862\n",
      "Epoch 5/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.6317 - loss: 0.6639 - val_accuracy: 0.6156 - val_loss: 0.6442\n",
      "Epoch 6/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 222ms/step - accuracy: 0.6240 - loss: 0.6515 - val_accuracy: 0.6344 - val_loss: 0.6308\n",
      "Epoch 7/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - accuracy: 0.6571 - loss: 0.6264 - val_accuracy: 0.6219 - val_loss: 0.6258\n",
      "Epoch 8/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.6773 - loss: 0.6094 - val_accuracy: 0.7000 - val_loss: 0.5981\n",
      "Epoch 9/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 0.6783 - loss: 0.6022 - val_accuracy: 0.6438 - val_loss: 0.6042\n",
      "Epoch 10/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 220ms/step - accuracy: 0.6756 - loss: 0.6260 - val_accuracy: 0.6656 - val_loss: 0.6024\n",
      "Epoch 11/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - accuracy: 0.6577 - loss: 0.6038 - val_accuracy: 0.6687 - val_loss: 0.5992\n",
      "Epoch 12/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - accuracy: 0.6951 - loss: 0.6108 - val_accuracy: 0.6375 - val_loss: 0.6212\n",
      "Epoch 13/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 220ms/step - accuracy: 0.6964 - loss: 0.5720 - val_accuracy: 0.6812 - val_loss: 0.5778\n",
      "Epoch 14/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 0.6910 - loss: 0.5983 - val_accuracy: 0.6594 - val_loss: 0.5951\n",
      "Epoch 15/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - accuracy: 0.7012 - loss: 0.5778 - val_accuracy: 0.7094 - val_loss: 0.5606\n",
      "Epoch 16/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 217ms/step - accuracy: 0.7020 - loss: 0.5770 - val_accuracy: 0.6406 - val_loss: 0.6485\n",
      "Epoch 17/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.6894 - loss: 0.5713 - val_accuracy: 0.5844 - val_loss: 0.7167\n",
      "Epoch 18/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.6777 - loss: 0.5833 - val_accuracy: 0.6687 - val_loss: 0.5961\n",
      "Epoch 19/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.7054 - loss: 0.5523 - val_accuracy: 0.6969 - val_loss: 0.5762\n",
      "Epoch 20/20\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.7263 - loss: 0.5500 - val_accuracy: 0.6531 - val_loss: 0.6349\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.7061 - loss: 0.6088\n",
      "Test Accuracy with RMSprop optimizer: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "optimizers = {\n",
    "    'Adam': tf.keras.optimizers.Adam(),\n",
    "    'SGD': tf.keras.optimizers.SGD(),\n",
    "    'RMSprop': tf.keras.optimizers.RMSprop()\n",
    "}\n",
    "\n",
    "# Train and evaluate models with different optimizers\n",
    "for optimizer_name, optimizer_instance in optimizers.items():\n",
    "    print(f\"Training model with {optimizer_name} optimizer...\")\n",
    "    \n",
    "    # Create CNN model\n",
    "    cnn_model = create_cnn(input_shape, num_classes)\n",
    "    \n",
    "    # Compile CNN model with the specified optimizer\n",
    "    cnn_model.compile(optimizer=optimizer_instance, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train CNN model\n",
    "    cnn_model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=20, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Evaluate CNN model\n",
    "    test_loss, test_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy with {optimizer_name} optimizer: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
